import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import pandas as pd
from loguru import logger
import re
import argparse

def extract_numeric_answer(question, reasoning_steps, llama_model, llama_tokenizer):
    messages = [
        {"role": "system", "content": "You are an AI assistant that extracts numeric answers from solutions."},
        {"role": "user", "content": f"Question: {question}\n\Solution:\n{reasoning_steps}\n\nThe solution is generated by an AI model. Identify and extract the final numeric answer from the solution. If the answer is not explicitly stated as a number, infer it if possible. If no numeric answer can be determined, respond with 'unknown'. Output only the numeric answer or 'unknown'."}
    ]
    
    input_ids = llama_tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        return_tensors="pt"
    ).to('cuda')
    
    with torch.no_grad():
        output = llama_model.generate(
            input_ids,
            max_new_tokens=256,
            temperature=0.1,
            num_return_sequences=1,
            pad_token_id=llama_tokenizer.eos_token_id
        )
    
    response = output[0]
    answer = llama_tokenizer.decode(response[input_ids.shape[-1]:], skip_special_tokens=True).strip()
    return answer

def verify_answer(question, predicted_answer, ground_truth_answer, llama_model, llama_tokenizer):
    messages = [
        {"role": "system", "content": "You are an AI assistant that verifies if the predicted answer matches the ground truth answer."},
        {"role": "user", "content": f"Question:{question}\n\nPredicted Answer: {predicted_answer}\n\nGround Truth Answer: {ground_truth_answer}\n\nDoes the predicted answer match the ground truth answer and directly address the question? If the absolute difference between their values is within 0.1, answer 'yes'; otherwise, answer 'no'. Respond only with 'yes' or 'no'. "}
    ]
    
    input_ids = llama_tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        return_tensors="pt"
    ).to('cuda')
    
    with torch.no_grad():
        output = llama_model.generate(
            input_ids,
            max_new_tokens=256,
            temperature=0.1,
            num_return_sequences=1,
            pad_token_id=llama_tokenizer.eos_token_id
        )
    
    response = output[0][input_ids.shape[-1]:]
    verification = llama_tokenizer.decode(response, skip_special_tokens=True).strip().lower()
    return verification

def main(args):
    # Load the llama3-8b model and tokenizer
    model_name = "meta-llama/Meta-Llama-3-8B-Instruct"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="cuda",
    )

    # Load the CSV file into a pandas DataFrame
    df = pd.read_csv(args.csv_file)

    question_column = "question"
    ground_truth_answer_column = "answer"

    answers = []
    answer_verifications = []
    for i, row in df.iterrows():
        logger.info('Index: {}', i)

        question = row[question_column]
        reasoning_steps = row[args.reasoning_column]
        gt_answer = row[ground_truth_answer_column]
        predicted_answer = extract_numeric_answer(question, reasoning_steps, model, tokenizer)
        logger.debug('Ground Truth Answer: {} Extracted Answer: {}', gt_answer, predicted_answer)

        answer_verification = verify_answer(question, predicted_answer, gt_answer, model, tokenizer)

        logger.debug('Answer Verification: {}', answer_verification)

        answers.append(predicted_answer)
        answer_verifications.append(answer_verification)

    # Add the extracted answers as a new column in the DataFrame
    df["extracted_answer"] = answers
    df["answer_verification"] = answer_verifications

    # Calculate the accuracy based on the first match of "yes" or "no"
    pattern = re.compile(r'\b(yes|no)\b', re.IGNORECASE)
    df['answer_verification_match'] = df['answer_verification'].apply(lambda x: pattern.search(x).group(1) if pattern.search(x) else '')
    accuracy = (df['answer_verification_match'] == 'yes').mean()

    logger.info("Accuracy: {:.2%}", accuracy)

    # Save the updated DataFrame back to the CSV file
    df.to_csv(args.output_file, index=False)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Extract numeric answers and verify them.")
    parser.add_argument("--csv_file", type=str, required=True, help="Path to the input CSV file")
    parser.add_argument("--reasoning_column", type=str, required=True, help="Column name for reasoning steps")
    parser.add_argument("--output_file", type=str, required=True, help="Path to the output CSV file")
    args = parser.parse_args()

    main(args)
